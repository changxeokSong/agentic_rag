# services/logging_system.py - ìë™í™” ì „ìš© ë¡œê¹… ë° ì•Œë¦¼ ì‹œìŠ¤í…œ

import json
import csv
import os
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, asdict
from enum import Enum
import threading
from pathlib import Path

from storage.postgresql_storage import PostgreSQLStorage
from utils.logger import setup_logger

logger = setup_logger(__name__)

class LogLevel(Enum):
    DEBUG = 0
    INFO = 1
    WARNING = 2
    ERROR = 3
    CRITICAL = 4

class EventType(Enum):
    SYSTEM = "SYSTEM"
    DECISION = "DECISION"
    ACTION = "ACTION"
    ALERT = "ALERT"
    ERROR = "ERROR"
    MANUAL = "MANUAL"
    EVALUATION = "EVALUATION"

@dataclass
class LogEntry:
    timestamp: datetime
    level: LogLevel
    event_type: EventType
    reservoir_id: str
    message: str
    details: Dict[str, Any]
    session_id: Optional[str] = None

@dataclass
class AlertRule:
    name: str
    conditions: Dict[str, Any]  # {"water_level": {"min": 0, "max": 120}, "pump_failures": 3}
    actions: List[str]  # ["log", "console", "file", "database"]
    enabled: bool = True
    last_triggered: Optional[datetime] = None
    cooldown_minutes: int = 5

class AutomationLogger:
    """ìë™í™” ì‹œìŠ¤í…œ ì „ìš© ë¡œê±°"""
    
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # ë¡œê·¸ íŒŒì¼ ì„¤ì •
        self.current_session = self._generate_session_id()
        self.log_files = {
            "main": self.log_dir / f"automation_{datetime.now().strftime('%Y%m%d')}.log",
            "events": self.log_dir / f"events_{datetime.now().strftime('%Y%m%d')}.csv",
            "decisions": self.log_dir / f"decisions_{datetime.now().strftime('%Y%m%d')}.json",
            "alerts": self.log_dir / f"alerts_{datetime.now().strftime('%Y%m%d')}.log"
        }
        
        # ë©”ëª¨ë¦¬ ë‚´ ë¡œê·¸ ë²„í¼
        self.log_buffer = []
        self.max_buffer_size = 1000
        
        # ì•Œë¦¼ ê·œì¹™
        self.alert_rules = self._setup_default_alert_rules()
        
        # PostgreSQL ì—°ê²°
        try:
            self.storage = PostgreSQLStorage.get_instance()
            self._setup_database_tables()
        except Exception as e:
            logger.error(f"PostgreSQL ì—°ê²° ì‹¤íŒ¨ (ë¡œê¹…): {e}")
            self.storage = None
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„±
        self.lock = threading.Lock()
        
        logger.info(f"ìë™í™” ë¡œê±° ì´ˆê¸°í™” ì™„ë£Œ - ì„¸ì…˜: {self.current_session}")

    def _generate_session_id(self) -> str:
        """ì„¸ì…˜ ID ìƒì„±"""
        return f"AUTO_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

    def _setup_default_alert_rules(self) -> List[AlertRule]:
        """ê¸°ë³¸ ì•Œë¦¼ ê·œì¹™ ì„¤ì •"""
        return [
            AlertRule(
                name="critical_water_level",
                conditions={"water_level_above": 100},
                actions=["log", "console", "file"],
                cooldown_minutes=10
            ),
            AlertRule(
                name="emergency_water_level", 
                conditions={"water_level_above": 120},
                actions=["log", "console", "file", "database"],
                cooldown_minutes=5
            ),
            AlertRule(
                name="pump_failure",
                conditions={"pump_control_failure": True},
                actions=["log", "console", "file"],
                cooldown_minutes=15
            ),
            AlertRule(
                name="arduino_disconnection",
                conditions={"arduino_connected": False},
                actions=["log", "console", "file"],
                cooldown_minutes=30
            ),
            AlertRule(
                name="multiple_pump_failures",
                conditions={"failed_pumps_count_above": 2},
                actions=["log", "console", "file", "database"],
                cooldown_minutes=20
            )
        ]

    def _setup_database_tables(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì„¤ì •"""
        if not self.storage:
            return
        
        try:
            # automation_logs í…Œì´ë¸” ìƒì„±
            create_table_sql = """
            CREATE TABLE IF NOT EXISTS automation_logs (
                id SERIAL PRIMARY KEY,
                timestamp TIMESTAMP NOT NULL,
                session_id VARCHAR(50),
                level VARCHAR(20) NOT NULL,
                event_type VARCHAR(20) NOT NULL,
                reservoir_id VARCHAR(50) NOT NULL,
                message TEXT NOT NULL,
                details JSONB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            
            CREATE INDEX IF NOT EXISTS idx_automation_logs_timestamp ON automation_logs(timestamp);
            CREATE INDEX IF NOT EXISTS idx_automation_logs_reservoir ON automation_logs(reservoir_id);
            CREATE INDEX IF NOT EXISTS idx_automation_logs_type ON automation_logs(event_type);
            """
            
            self.storage.execute_query(create_table_sql, commit=True)
            logger.info("ìë™í™” ë¡œê·¸ í…Œì´ë¸” ì¤€ë¹„ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì„¤ì • ì˜¤ë¥˜: {e}")

    def log(self, level: LogLevel, event_type: EventType, reservoir_id: str, message: str, details: Dict[str, Any] = None):
        """ë¡œê·¸ ê¸°ë¡"""
        with self.lock:
            # ì•ˆì „í•œ enum ì •ê·œí™” (ë¬¸ìì—´/ì •ìˆ˜ ì…ë ¥ í—ˆìš©)
            try:
                if isinstance(level, str):
                    level_enum = getattr(LogLevel, level.upper(), LogLevel.INFO)
                elif isinstance(level, int):
                    level_enum = LogLevel(level) if level in [e.value for e in LogLevel] else LogLevel.INFO
                elif isinstance(level, LogLevel):
                    level_enum = level
                else:
                    level_enum = LogLevel.INFO
            except Exception:
                level_enum = LogLevel.INFO

            try:
                if isinstance(event_type, str):
                    event_enum = getattr(EventType, event_type.upper(), EventType.SYSTEM)
                elif isinstance(event_type, EventType):
                    event_enum = event_type
                else:
                    event_enum = EventType.SYSTEM
            except Exception:
                event_enum = EventType.SYSTEM

            entry = LogEntry(
                timestamp=datetime.now(),
                level=level_enum,
                event_type=event_enum,
                reservoir_id=reservoir_id,
                message=message,
                details=details or {},
                session_id=self.current_session
            )
            
            # ë²„í¼ì— ì¶”ê°€
            self.log_buffer.append(entry)
            
            # ë²„í¼ í¬ê¸° ì œí•œ
            if len(self.log_buffer) > self.max_buffer_size:
                self.log_buffer = self.log_buffer[-self.max_buffer_size:]
            
            # ë‹¤ì–‘í•œ ì¶œë ¥ ìˆ˜í–‰
            self._write_to_file(entry)
            self._write_to_console(entry)
            self._write_to_csv(entry)
            
            # íŠ¹ë³„í•œ ì´ë²¤íŠ¸ëŠ” JSONìœ¼ë¡œ ë³„ë„ ì €ì¥
            if event_type == EventType.DECISION:
                self._write_decision_to_json(entry)
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            if self.storage and level.value >= LogLevel.INFO.value:
                self._write_to_database(entry)
            
            # ì•Œë¦¼ ê·œì¹™ í™•ì¸
            self._check_alert_rules(entry)

    def _write_to_file(self, entry: LogEntry):
        """ë©”ì¸ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡"""
        try:
            log_line = f"[{entry.timestamp.strftime('%Y-%m-%d %H:%M:%S')}] [{entry.level.name}] [{entry.event_type.value}] [{entry.reservoir_id}] {entry.message}\n"
            
            with open(self.log_files["main"], "a", encoding="utf-8") as f:
                f.write(log_line)
                
        except Exception as e:
            logger.error(f"íŒŒì¼ ë¡œê·¸ ì“°ê¸° ì˜¤ë¥˜: {e}")

    def _write_to_console(self, entry: LogEntry):
        """ì½˜ì†”ì— ì¶œë ¥ - ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ì§ì ‘ print ì‚¬ìš©"""
        if entry.level.value >= LogLevel.INFO.value:
            timestamp = entry.timestamp.strftime('%H:%M:%S')
            prefix = "ğŸ¤– [AUTO]"
            message = f"[{timestamp}] {prefix} [{entry.event_type.value}] {entry.reservoir_id}: {entry.message}"
            
            # ì§ì ‘ ì¶œë ¥í•˜ì—¬ ì¤‘ë³µ ë¡œê·¸ ë°©ì§€
            print(message)

    def _write_to_csv(self, entry: LogEntry):
        """CSV íŒŒì¼ì— ì´ë²¤íŠ¸ ê¸°ë¡"""
        try:
            file_exists = self.log_files["events"].exists()
            
            with open(self.log_files["events"], "a", newline="", encoding="utf-8-sig") as f:
                writer = csv.writer(f)
                
                # í—¤ë” ì¶”ê°€ (íŒŒì¼ì´ ìƒˆë¡œ ìƒì„±ëœ ê²½ìš°)
                if not file_exists:
                    writer.writerow([
                        "timestamp", "session_id", "level", "event_type", 
                        "reservoir_id", "message", "details"
                    ])
                
                writer.writerow([
                    entry.timestamp.isoformat(),
                    entry.session_id,
                    entry.level.name,
                    entry.event_type.value,
                    entry.reservoir_id,
                    entry.message,
                    json.dumps(entry.details, ensure_ascii=False, separators=(',', ':'))
                ])
                
        except Exception as e:
            logger.error(f"CSV ë¡œê·¸ ì“°ê¸° ì˜¤ë¥˜: {e}")

    def _write_decision_to_json(self, entry: LogEntry):
        """ì˜ì‚¬ê²°ì • ë¡œê·¸ë¥¼ JSON íŒŒì¼ì— ì €ì¥"""
        try:
            decision_data = {
                "timestamp": entry.timestamp.isoformat(),
                "session_id": entry.session_id,
                "reservoir_id": entry.reservoir_id,
                "message": entry.message,
                "details": entry.details
            }
            
            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            decisions = []
            if self.log_files["decisions"].exists():
                try:
                    with open(self.log_files["decisions"], "r", encoding="utf-8") as f:
                        decisions = json.load(f)
                except:
                    decisions = []
            
            decisions.append(decision_data)
            
            # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
            if len(decisions) > 100:
                decisions = decisions[-100:]
            
            with open(self.log_files["decisions"], "w", encoding="utf-8") as f:
                json.dump(decisions, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.error(f"ì˜ì‚¬ê²°ì • JSON ë¡œê·¸ ì“°ê¸° ì˜¤ë¥˜: {e}")

    def _write_to_database(self, entry: LogEntry):
        """ë°ì´í„°ë² ì´ìŠ¤ì— ë¡œê·¸ ì €ì¥"""
        try:
            if not self.storage:
                return
            
            insert_sql = """
            INSERT INTO automation_logs (timestamp, session_id, level, event_type, reservoir_id, message, details)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            """
            
            self.storage.execute_query(
                insert_sql,
                params=(
                    entry.timestamp,
                    entry.session_id,
                    entry.level.name,
                    entry.event_type.value,
                    entry.reservoir_id,
                    entry.message,
                    json.dumps(entry.details)
                ),
                commit=True
            )
            
        except Exception as e:
            logger.debug(f"ë°ì´í„°ë² ì´ìŠ¤ ë¡œê·¸ ì €ì¥ ì˜¤ë¥˜: {e}")

    def _check_alert_rules(self, entry: LogEntry):
        """ì•Œë¦¼ ê·œì¹™ í™•ì¸ ë° ì‹¤í–‰"""
        try:
            current_time = datetime.now()
            
            for rule in self.alert_rules:
                if not rule.enabled:
                    continue
                
                # ì¿¨ë‹¤ìš´ í™•ì¸
                if (rule.last_triggered and 
                    current_time - rule.last_triggered < timedelta(minutes=rule.cooldown_minutes)):
                    continue
                
                # ì¡°ê±´ í™•ì¸
                if self._match_alert_conditions(entry, rule.conditions):
                    self._trigger_alert(entry, rule)
                    rule.last_triggered = current_time
                    
        except Exception as e:
            logger.error(f"ì•Œë¦¼ ê·œì¹™ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")

    def _match_alert_conditions(self, entry: LogEntry, conditions: Dict[str, Any]) -> bool:
        """ì•Œë¦¼ ì¡°ê±´ ë§¤ì¹­"""
        try:
            details = entry.details
            
            # ìˆ˜ìœ„ ê¸°ë°˜ ì¡°ê±´
            if "water_level_above" in conditions:
                water_level = details.get("current_level", 0)
                if water_level > conditions["water_level_above"]:
                    return True
            
            # íŒí”„ ì‹¤íŒ¨ ì¡°ê±´
            if "pump_control_failure" in conditions:
                pump_success = details.get("result", {}).get("success", True)
                if not pump_success and conditions["pump_control_failure"]:
                    return True
            
            # ì•„ë‘ì´ë…¸ ì—°ê²° ì¡°ê±´ (ëª…ì‹œì ìœ¼ë¡œ ì—°ê²° ìƒíƒœê°€ ì œê³µëœ ê²½ìš°ë§Œ)
            if "arduino_connected" in conditions:
                # detailsì— arduino_connectedê°€ ëª…ì‹œì ìœ¼ë¡œ ìˆì„ ë•Œë§Œ í™•ì¸
                if "arduino_connected" in details:
                    arduino_connected = details.get("arduino_connected")
                    if arduino_connected != conditions["arduino_connected"]:
                        return True
            
            # ë‹¤ì¤‘ íŒí”„ ì‹¤íŒ¨ ì¡°ê±´
            if "failed_pumps_count_above" in conditions:
                failed_pumps = details.get("failed_pumps_count", 0)
                if failed_pumps > conditions["failed_pumps_count_above"]:
                    return True
            
            return False
            
        except Exception as e:
            logger.error(f"ì•Œë¦¼ ì¡°ê±´ ë§¤ì¹­ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def _trigger_alert(self, entry: LogEntry, rule: AlertRule):
        """ì•Œë¦¼ ì‹¤í–‰"""
        alert_message = f"ğŸš¨ ALERT: {rule.name} - {entry.message}"
        
        try:
            # ì½˜ì†” ì¶œë ¥ (ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ì§ì ‘ print ì‚¬ìš©)
            if "console" in rule.actions:
                timestamp = entry.timestamp.strftime('%H:%M:%S')
                print(f"[{timestamp}] ğŸ¤– [AUTO] [ALERT] {entry.reservoir_id}: {alert_message}")
            
            # íŒŒì¼ ê¸°ë¡
            if "file" in rule.actions:
                with open(self.log_files["alerts"], "a", encoding="utf-8") as f:
                    f.write(f"[{entry.timestamp.isoformat()}] {alert_message}\n")
            
            # ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë¡ (ì¬ê·€ í˜¸ì¶œ ë°©ì§€)
            if "database" in rule.actions and self.storage:
                try:
                    insert_sql = """
                    INSERT INTO automation_logs (timestamp, session_id, level, event_type, reservoir_id, message, details)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                    """
                    
                    self.storage.execute_query(
                        insert_sql,
                        params=(
                            entry.timestamp,
                            entry.session_id,
                            'CRITICAL',
                            'ALERT',
                            entry.reservoir_id,
                            f"Alert triggered: {rule.name}",
                            json.dumps({"rule": rule.name, "original_message": entry.message})
                        ),
                        commit=True
                    )
                except Exception as db_e:
                    print(f"ë°ì´í„°ë² ì´ìŠ¤ ì•Œë¦¼ ì €ì¥ ì˜¤ë¥˜: {db_e}")
            
        except Exception as e:
            print(f"ì•Œë¦¼ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")

    # í¸ì˜ ë©”ì„œë“œë“¤
    def info(self, event_type: EventType, reservoir_id: str, message: str, details: Dict[str, Any] = None):
        self.log(LogLevel.INFO, event_type, reservoir_id, message, details)
    
    def warning(self, event_type: EventType, reservoir_id: str, message: str, details: Dict[str, Any] = None):
        self.log(LogLevel.WARNING, event_type, reservoir_id, message, details)
    
    def error(self, event_type: EventType, reservoir_id: str, message: str, details: Dict[str, Any] = None):
        self.log(LogLevel.ERROR, event_type, reservoir_id, message, details)
    
    def critical(self, event_type: EventType, reservoir_id: str, message: str, details: Dict[str, Any] = None):
        self.log(LogLevel.CRITICAL, event_type, reservoir_id, message, details)

    def get_recent_logs(self, limit: int = 50, level: LogLevel = LogLevel.DEBUG) -> List[Dict[str, Any]]:
        """ìµœê·¼ ë¡œê·¸ ì¡°íšŒ"""
        with self.lock:
            try:
                # level íŒŒë¼ë¯¸í„°ê°€ LogLevel enumì¸ì§€ í™•ì¸í•˜ê³  ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                if isinstance(level, str):
                    # ë¬¸ìì—´ì¸ ê²½ìš° LogLevelë¡œ ë³€í™˜
                    level_value = getattr(LogLevel, level.upper(), LogLevel.DEBUG).value
                elif isinstance(level, LogLevel):
                    level_value = level.value
                else:
                    level_value = LogLevel.DEBUG.value
                
                filtered_logs = [
                    entry for entry in self.log_buffer 
                    if hasattr(entry.level, 'value') and entry.level.value >= level_value
                ]
                
                return [
                    {
                        "timestamp": entry.timestamp.isoformat() if hasattr(entry.timestamp, 'isoformat') else str(entry.timestamp),
                        "level": entry.level.name if hasattr(entry.level, 'name') else str(entry.level),
                        "event_type": entry.event_type.value if hasattr(entry.event_type, 'value') else str(entry.event_type),
                        "reservoir_id": str(entry.reservoir_id),
                        "message": str(entry.message),
                        "details": entry.details if entry.details else {}
                    }
                    for entry in filtered_logs[-limit:]
                ]
            except Exception as e:
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
                logger.error(f"ë¡œê·¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
                return []

    def get_logs_by_reservoir(self, reservoir_id: str, limit: int = 30) -> List[Dict[str, Any]]:
        """íŠ¹ì • ë°°ìˆ˜ì§€ ë¡œê·¸ ì¡°íšŒ"""
        with self.lock:
            try:
                reservoir_logs = [
                    entry for entry in self.log_buffer 
                    if str(entry.reservoir_id) == str(reservoir_id)
                ]
                
                return [
                    {
                        "timestamp": entry.timestamp.isoformat() if hasattr(entry.timestamp, 'isoformat') else str(entry.timestamp),
                        "level": entry.level.name if hasattr(entry.level, 'name') else str(entry.level),
                        "event_type": entry.event_type.value if hasattr(entry.event_type, 'value') else str(entry.event_type),
                        "reservoir_id": str(entry.reservoir_id),
                        "message": str(entry.message),
                        "details": entry.details if entry.details else {}
                    }
                    for entry in reservoir_logs[-limit:]
                ]
            except Exception as e:
                logger.error(f"ë°°ìˆ˜ì§€ë³„ ë¡œê·¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
                return []

    def get_decision_history(self, limit: int = 20) -> List[Dict[str, Any]]:
        """ì˜ì‚¬ê²°ì • ì´ë ¥ ì¡°íšŒ"""
        try:
            if not self.log_files["decisions"].exists():
                return []
            
            with open(self.log_files["decisions"], "r", encoding="utf-8") as f:
                decisions = json.load(f)
                return decisions[-limit:] if decisions else []
                
        except Exception as e:
            logger.error(f"ì˜ì‚¬ê²°ì • ì´ë ¥ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []

    def export_logs(self, start_date: datetime, end_date: datetime, format: str = "csv") -> str:
        """ë¡œê·¸ ë‚´ë³´ë‚´ê¸°"""
        try:
            filtered_logs = [
                entry for entry in self.log_buffer
                if start_date <= entry.timestamp <= end_date
            ]
            
            timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            if format.lower() == "csv":
                export_file = self.log_dir / f"export_{timestamp_str}.csv"
                
                with open(export_file, "w", newline="", encoding="utf-8-sig") as f:
                    writer = csv.writer(f)
                    writer.writerow([
                        "timestamp", "level", "event_type", "reservoir_id", "message", "details"
                    ])
                    
                    for entry in filtered_logs:
                        writer.writerow([
                            entry.timestamp.isoformat(),
                            entry.level.name,
                            entry.event_type.value,
                            entry.reservoir_id,
                            entry.message,
                            json.dumps(entry.details, ensure_ascii=False, separators=(',', ':'))
                        ])
                        
            elif format.lower() == "json":
                export_file = self.log_dir / f"export_{timestamp_str}.json"
                
                export_data = [
                    {
                        "timestamp": entry.timestamp.isoformat(),
                        "level": entry.level.name,
                        "event_type": entry.event_type.value,
                        "reservoir_id": entry.reservoir_id,
                        "message": entry.message,
                        "details": entry.details
                    }
                    for entry in filtered_logs
                ]
                
                with open(export_file, "w", encoding="utf-8") as f:
                    json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            return str(export_file)
            
        except Exception as e:
            logger.error(f"ë¡œê·¸ ë‚´ë³´ë‚´ê¸° ì˜¤ë¥˜: {e}")
            raise

    def add_alert_rule(self, rule: AlertRule) -> bool:
        """ì•Œë¦¼ ê·œì¹™ ì¶”ê°€"""
        try:
            self.alert_rules.append(rule)
            self.info(EventType.SYSTEM, "system", f"ì•Œë¦¼ ê·œì¹™ ì¶”ê°€: {rule.name}")
            return True
            
        except Exception as e:
            logger.error(f"ì•Œë¦¼ ê·œì¹™ ì¶”ê°€ ì˜¤ë¥˜: {e}")
            return False

    def cleanup_old_logs(self, days_to_keep: int = 30):
        """ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì •ë¦¬"""
        try:
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)
            
            for log_file in self.log_dir.glob("*.log"):
                if log_file.stat().st_mtime < cutoff_date.timestamp():
                    log_file.unlink()
                    logger.info(f"ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì‚­ì œ: {log_file}")
            
            for csv_file in self.log_dir.glob("*.csv"):
                if csv_file.stat().st_mtime < cutoff_date.timestamp():
                    csv_file.unlink()
                    logger.info(f"ì˜¤ë˜ëœ CSV íŒŒì¼ ì‚­ì œ: {csv_file}")
                    
        except Exception as e:
            logger.error(f"ë¡œê·¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# ì „ì—­ ìë™í™” ë¡œê±° ì¸ìŠ¤í„´ìŠ¤
_global_automation_logger = None

def get_automation_logger() -> AutomationLogger:
    """ì „ì—­ ìë™í™” ë¡œê±° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_automation_logger
    if _global_automation_logger is None:
        _global_automation_logger = AutomationLogger()
    return _global_automation_logger