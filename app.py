# app.py - Streamlit ì•± (í™˜ê²½ë³€ìˆ˜ í™œìš©)

import streamlit as st
import asyncio
import nest_asyncio
import time
import os
import json
from models.lm_studio import LMStudioClient
from retrieval.vector_store import VectorStore
from core.orchestrator import Orchestrator
from utils.logger import setup_logger
from config import print_config, DEBUG_MODE, ENABLED_TOOLS

# ë¹„ë™ê¸° ì§€ì›ì„ ìœ„í•œ nest_asyncio ì„¤ì •
nest_asyncio.apply()

# ë¡œê±° ì„¤ì •
logger = setup_logger(__name__)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'system_initialized' not in st.session_state:
    st.session_state.system_initialized = False

if 'debug_info' not in st.session_state:
    st.session_state.debug_info = {}

if 'config_info' not in st.session_state:
    st.session_state.config_info = print_config()

def initialize_system():
    """AgenticRAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    with st.spinner("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘..."):
        try:
            # LM Studio í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            lm_studio_client = LMStudioClient()
            
            # ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” (vector_tool ë„êµ¬ê°€ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ)
            vector_store = None
            if "vector_tool" in ENABLED_TOOLS:
                vector_store = VectorStore()
            
            # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”
            orchestrator = Orchestrator(lm_studio_client, vector_store)
            
            # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state.lm_studio_client = lm_studio_client
            st.session_state.vector_store = vector_store
            st.session_state.orchestrator = orchestrator
            st.session_state.system_initialized = True
            
            # ì„¤ì • ì •ë³´ ì—…ë°ì´íŠ¸
            st.session_state.config_info = print_config()
            
            # ëª¨ë¸ ì •ë³´ í™•ì¸
            model_info = lm_studio_client.get_model_info()
            st.session_state.model_info = model_info
            
            # í™œì„±í™”ëœ ë„êµ¬ ì •ë³´
            if hasattr(orchestrator, 'tool_manager'):
                st.session_state.tool_info = orchestrator.tool_manager.get_tool_info()
            
            return True
        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
            st.error(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return False

async def process_query_async(query):
    """ì§ˆì˜ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬"""
    orchestrator = st.session_state.orchestrator
    start_time = time.time()
    
    try:
        result = await orchestrator.process_query(query)
        
        # ë””ë²„ê·¸ ì •ë³´ ì—…ë°ì´íŠ¸
        st.session_state.debug_info = {
            "query": query,
            "tool_calls": result["tool_calls"],
            "tool_results": result["tool_results"],
            "processing_time": f"{time.time() - start_time:.2f} ì´ˆ"
        }
        
        return result["response"]
    except Exception as e:
        logger.error(f"ì§ˆì˜ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return f"ì§ˆì˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def upload_and_index_files():
    st.subheader("ë¬¸ì„œ ì—…ë¡œë“œ ë° ìƒ‰ì¸")
    uploaded_files = st.file_uploader("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (txt, pdf)", type=["txt", "pdf"], accept_multiple_files=True)
    if uploaded_files and st.session_state.system_initialized:
        docs = []
        for file in uploaded_files:
            file_path = f"/tmp/{file.name}"
            with open(file_path, "wb") as f:
                f.write(file.getbuffer())
            if file.name.lower().endswith(".txt"):
                loaded = DocumentLoader.load_text(file_path)
            elif file.name.lower().endswith(".pdf"):
                loaded = DocumentLoader.load_pdf(file_path)
            else:
                loaded = []
            docs.extend(loaded)
        # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
        vector_store = st.session_state.vector_store
        if vector_store:
            vector_store.add_texts([doc.page_content for doc in docs], "user_uploads")
            st.success(f"{len(docs)}ê°œ ë¬¸ì„œê°€ ìƒ‰ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.error("ë²¡í„° ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def main():
    """Streamlit ì•± ë©”ì¸ í•¨ìˆ˜"""
    st.set_page_config(
        page_title="AgenticRAG + LM Studio",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    
    # ì œëª©
    st.title("AgenticRAG + LM Studio + LangChain + Function Calling")
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ì‹œìŠ¤í…œ ì„¤ì •")
        
        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ì‹œìŠ¤í…œ ì´ˆê¸°í™”"):
            if initialize_system():
                st.success("ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                st.error("ì‹œìŠ¤í…œ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        if st.session_state.system_initialized:
            st.success("ì‹œìŠ¤í…œ ìƒíƒœ: ì´ˆê¸°í™”ë¨")
            
            # ëª¨ë¸ ì •ë³´ í‘œì‹œ
            if 'model_info' in st.session_state:
                st.subheader("ëª¨ë¸ ì •ë³´")
                model_info = st.session_state.model_info
                st.write(f"ëª¨ë¸: **{model_info['model']}**")
                st.write(f"API ìƒíƒœ: {'âœ… ì—°ê²°ë¨' if model_info['api_available'] else 'âŒ ì—°ê²° ì•ˆë¨'}")
        else:
            st.warning("ì‹œìŠ¤í…œ ìƒíƒœ: ì´ˆê¸°í™” í•„ìš”")
        
        # í™˜ê²½ ì„¤ì • í‘œì‹œ
        with st.expander("í™˜ê²½ ì„¤ì •"):
            if 'config_info' in st.session_state:
                config_info = st.session_state.config_info
                st.json(config_info)
        
        # ë””ë²„ê·¸ ëª¨ë“œ
        debug_mode = st.checkbox("ë””ë²„ê·¸ ëª¨ë“œ", value=DEBUG_MODE)
        
        # ë„êµ¬ ì •ë³´ í‘œì‹œ
        if st.session_state.system_initialized and 'tool_info' in st.session_state:
            st.subheader("í™œì„±í™”ëœ ë„êµ¬")
            tool_info = st.session_state.tool_info
            for name, info in tool_info.items():
                st.write(f"- **{info['name']}**: {info['description']}")
    
    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™” í™•ì¸
        if not st.session_state.system_initialized:
            if initialize_system():
                st.success("ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                st.error("ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ 'ì‹œìŠ¤í…œ ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
        
        # ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # ì‘ë‹µ ìƒì„±
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                    if st.session_state.system_initialized:
                        # ë¹„ë™ê¸° ì²˜ë¦¬ ì‹¤í–‰
                        response = asyncio.run(process_query_async(prompt))
                        message_placeholder.markdown(response)
                        st.session_state.messages.append({"role": "assistant", "content": response})
                    else:
                        error_msg = "ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ 'ì‹œìŠ¤í…œ ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”."
                        message_placeholder.error(error_msg)
                        st.session_state.messages.append({"role": "assistant", "content": error_msg})
    
    with col2:
        # ë¬¸ì„œ ì—…ë¡œë“œ ë° ìƒ‰ì¸ UI
        upload_and_index_files()
        # ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ (ë””ë²„ê·¸ ëª¨ë“œê°€ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ)
        if debug_mode and st.session_state.debug_info:
            st.header("ì²˜ë¦¬ ì •ë³´")
            debug_info = st.session_state.debug_info
            
            st.subheader("ì‚¬ìš©ì ì§ˆì˜")
            st.write(debug_info.get("query", "N/A"))
            
            st.subheader("ì„ íƒëœ ë„êµ¬")
            tool_call = debug_info.get("tool_calls", {})
            if tool_call:
                if isinstance(tool_call, list):
                    for i, call in enumerate(tool_call, 1):
                        st.write(f"ë„êµ¬ {i}: `{call.get('name', 'N/A')}`")
                        st.write("ì¸ì:")
                        st.json(call.get("arguments", {}))
                elif isinstance(tool_call, dict):
                    st.write(f"ë„êµ¬: `{tool_call.get('name', 'N/A')}`")
                    st.write("ì¸ì:")
                    st.json(tool_call.get("arguments", {}))
            else:
                st.write("ì„ íƒëœ ë„êµ¬ ì—†ìŒ")
            
            st.subheader("ë„êµ¬ ì‹¤í–‰ ê²°ê³¼")
            tool_results = debug_info.get("tool_results", {})
            for tool_name, result in tool_results.items():
                st.write(f"ë„êµ¬: `{tool_name}`")
                with st.expander("ê²°ê³¼ ë³´ê¸°"):
                    st.write(result)
            
            st.subheader("ì²˜ë¦¬ ì‹œê°„")
            st.write(debug_info.get("processing_time", "N/A"))

if __name__ == "__main__":
    main()